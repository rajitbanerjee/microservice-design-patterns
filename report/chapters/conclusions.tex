\chapter{Conclusions}

In conclusion, it is appropriate to reflect on the performance impact of microservices, design patterns, as well as the interpretation of case study evaluation results.

\section{Summary}

With the rising popularity of microservices, the number of systems migrating from monolithic to fine-grained microservice architecture is increasing by the day. Design patterns are essential to developers working with microservices, with every effort made to avoid anti-patterns which can hinder system performance.

Applying the most suitable design patterns for a given business use case is critical to achieving a functional system, and importantly, a \textit{performant} system able to deal with changing demand. Performance engineering is a vital part of the software development lifecycle, and clear objectives must be set to achieve the best performance at a given budget.

By building two web applications using a wide range of microservice design patterns, the performance benefits and shortcomings of each pattern were clearly demonstrated. While synchronous REST APIs are required for communication with some clients (e.g. frontend/UI), adopting an asynchronous strategy such as messaging for internal communication is highly recommended in order to avoid client blocking.

For microservices exposing an API for clients, using an API gateway along with automatic service discovery greatly reduces the necessary effort in client-side code. When using message queues, correctly configuring the infrastructure to use adequate hardware resources is an important task. Monitoring and observability patterns are crucial to tracking system performance over time, especially with useful visualisations instead of simple log dumps. Some design patterns such as externalising configuration, having a separate database per service, or using Docker to deploy a single service instance per container, are extremely useful and applicable to the vast majority of microservice-based applications.

Evaluation of case studies in this project suggests the following key takeaways:
\begin{itemize}
  \item Choosing an appropriate evaluation strategy is vital and is dependent on clear, pre-defined performance goals.
  \item Performance modelling and manual API testing are useful in the early stages of development. Any performance regressions and bottlenecks can be identified by modelling and then verified by large-scale testing. In the above case studies, the API gateway and Broker services are shown to be potential performance bottlenecks (single point of entry and failure e.g. due to congestion) and are hence prime candidates for service scaling to avoid issues.
  \item Automated performance testing, such as load testing, is essential for reliable performance analysis. Simple load testing reveals that the first case study (API gateway + REST) was observed to be approximately \textbf{25\%} slower (response time) and \textbf{7} times more error-prone on average to fetch an aggregated list of movie showtimes from all services,  under heavy load (100 threads) compared to the much faster and more reliable second case study (asynchronous messaging). However, when contacting a single cinema service to make a reservation, the API gateway triumphs with about \textbf{5} times faster responses compared to the queueing system. There were several factors (both hardware and software configurations) affecting the observed results, and it is quite possible to further optimise the services to obtain more distinctive results in each case study. Importantly, as long as common anti-patterns are avoided, no single design pattern is superior to another: the choice between similar patterns should depend on the business requirement.
  \item Since performance measurements can vary significantly, ensuring reliability through multiple test iterations is required. Data smoothing techniques should also be applied to obtain more usable plots.
\end{itemize}

Overall, this work has been a success in implementing various common microservice design patterns and analysing their performance impact. As is the case with all projects, there is  a scope for improvement, to be built upon and continued in future works.

\section{Future Work}

This project has a number of limitations that could be tackled by similar projects in the future. First and foremost, countless microservice design patterns and anti-patterns are constantly evolving and could be demonstrated through further case studies. Moreover, showing the migration process from monoliths to microservices using refactoring patterns should be an insightful study.

Today, the vast majority of microservices are deployed in the cloud (AWS, Google Cloud Platform, Microsoft Azure, and the like), thanks to various benefits such as ease of scalability and auto-provisioning resources, faster release, reduced cost, ease of management, and much more. Consequently, several cloud-specific design patterns have emerged. With cloud deployment, the use of container orchestration tools like Kubernetes are indispensable in the industry for managing a large number of containerised services, and to enable ease of scaling, reliability and fault tolerance.

To evaluate microservice-based applications, only simple and limited load testing was carried out in this project, entrusting more rigorous stress, spike and integration tests to future studies.

In the end, performance must not be an afterthought in the lifecycle, since delivering well-performing systems is arguably equally important as software functionality. Practices involving microservice architectures are still growing and developing constantly, and the shape they take in the future would be positively impacted by engineering and management teams taking measures to integrate performance considerations into the development process.
